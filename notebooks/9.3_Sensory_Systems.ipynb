{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9.3: Sensory System Explorer\n",
    "## Chapter 9: The Information Revolution - Nervous Systems\n\n",
    "### \ud83c\udfaf Learning Objectives\n",
    "- Compare sensory capabilities across vertebrates\n",
    "- Explore visual, auditory, and chemical detection ranges\n",
    "- Analyze specialized sensory systems (echolocation, electroreception)\n",
    "- Understand sensory trade-offs and adaptations\n\n",
    "### \ud83d\udcd6 Connection to Chapter 9\n",
    "This lab integrates concepts from **Section 9.4: Sensory Specialists**:\n",
    "- Universal sensory principles\n",
    "- Vision across species (mantis shrimp, birds, mammals)\n",
    "- Echolocation (dolphins, bats)\n",
    "- Electroreception (sharks, platypus)\n",
    "- Olfactory navigation (salmon)\n\n",
    "### \ud83d\udc41\ufe0f The Question\n",
    "What would the world look like through a mantis shrimp's eyes? Or sound like to a dolphin? Let's explore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GOOGLE COLAB SETUP - RUN THIS FIRST ===\n",
    "try:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "    print(\"\u2713 Widgets enabled\")\n",
    "except:\n",
    "    print(\"\u2713 Running outside Colab\")\n\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import *\n",
    "from IPython.display import display, clear_output\n",
    "from datetime import datetime\n",
    "import os\n\n",
    "print(\"\u2713 Ready to explore sensory systems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Sensory Capabilities Database\n\n",
    "Real data from Chapter 9 case studies and scientific literature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensory capabilities database\n",
    "species_sensory = {\n",
    "    'Human': {\n",
    "        'vision_nm': [380, 750],  # wavelength range\n",
    "        'hearing_hz': [20, 20000],\n",
    "        'olfactory': 'Moderate',\n",
    "        'special': [],\n",
    "        'color_receptors': 3,\n",
    "        'desc': 'Trichromatic vision. Good hearing range. Moderate olfaction. '\n",
    "                'No specialized sensory systems.'\n",
    "    },\n",
    "    'Mantis Shrimp': {\n",
    "        'vision_nm': [300, 720],  # Extended into UV\n",
    "        'hearing_hz': None,\n",
    "        'olfactory': 'Good',\n",
    "        'special': ['Polarization vision', 'UV vision'],\n",
    "        'color_receptors': 16,\n",
    "        'desc': 'Most complex visual system known! 16 color receptors vs human 3. '\n",
    "                'Can see UV and polarized light. Detects circular polarization.'\n",
    "    },\n",
    "    'Pigeon': {\n",
    "        'vision_nm': [300, 700],\n",
    "        'hearing_hz': [10, 10000],\n",
    "        'olfactory': 'Good',\n",
    "        'special': ['UV vision', 'Magnetic sense'],\n",
    "        'color_receptors': 4,\n",
    "        'desc': 'Tetrachromatic vision (4 receptors). UV vision for navigation. '\n",
    "                'Magnetoreception for orientation. Excellent visual acuity.'\n",
    "    },\n",
    "    'Dog': {\n",
    "        'vision_nm': [430, 700],  # No red perception\n",
    "        'hearing_hz': [40, 60000],\n",
    "        'olfactory': 'Exceptional',\n",
    "        'special': ['Olfactory'],\n",
    "        'color_receptors': 2,\n",
    "        'desc': 'Dichromatic vision (blue-yellow). EXCEPTIONAL olfaction: '\n",
    "                '10,000-100,000\u00d7 better than humans. 300 million olfactory receptors.'\n",
    "    },\n",
    "    'Dolphin': {\n",
    "        'vision_nm': [400, 600],\n",
    "        'hearing_hz': [75, 150000],\n",
    "        'olfactory': 'Poor',\n",
    "        'special': ['Echolocation'],\n",
    "        'color_receptors': 1,\n",
    "        'desc': 'Sophisticated biosonar! Echolocation at 150kHz. Can distinguish '\n",
    "                'objects by material and internal structure. Monochromatic vision.'\n",
    "    },\n",
    "    'Bat': {\n",
    "        'vision_nm': [400, 700],\n",
    "        'hearing_hz': [1000, 120000],\n",
    "        'olfactory': 'Good',\n",
    "        'special': ['Echolocation'],\n",
    "        'color_receptors': 2,\n",
    "        'desc': 'Ultrasonic echolocation 20-120kHz. Can detect insects mid-flight. '\n",
    "                'Some species use frequency-modulated calls for detailed imaging.'\n",
    "    },\n",
    "    'Shark (Hammerhead)': {\n",
    "        'vision_nm': [400, 700],\n",
    "        'hearing_hz': [10, 800],\n",
    "        'olfactory': 'Exceptional',\n",
    "        'special': ['Electroreception', 'Lateral line'],\n",
    "        'color_receptors': 1,\n",
    "        'desc': 'Ampullae of Lorenzini detect electric fields down to 5nV/cm! '\n",
    "                'Can sense muscle contractions of prey. Exceptional olfaction '\n",
    "                '(detect 1 part per billion). Lateral line detects water movement.'\n",
    "    },\n",
    "    'Salmon': {\n",
    "        'vision_nm': [350, 650],\n",
    "        'hearing_hz': [50, 1000],\n",
    "        'olfactory': 'Exceptional',\n",
    "        'special': ['Olfactory navigation', 'Magnetic sense'],\n",
    "        'color_receptors': 4,\n",
    "        'desc': 'EXTRAORDINARY olfactory navigation! Imprints on home stream odor. '\n",
    "                'Returns after years at sea detecting parts per trillion. '\n",
    "                'Uses magnetic cues for ocean navigation.'\n",
    "    },\n",
    "    'Owl': {\n",
    "        'vision_nm': [380, 700],\n",
    "        'hearing_hz': [200, 12000],\n",
    "        'olfactory': 'Poor',\n",
    "        'special': ['Night vision', 'Asymmetric ears'],\n",
    "        'color_receptors': 3,\n",
    "        'desc': 'Exceptional night vision (100\u00d7 human sensitivity). Asymmetric ear '\n",
    "                'placement for 3D sound localization. Can hunt in complete darkness '\n",
    "                'by sound alone.'\n",
    "    },\n",
    "    'Snake (Pit Viper)': {\n",
    "        'vision_nm': [400, 700],\n",
    "        'hearing_hz': [50, 1000],\n",
    "        'olfactory': 'Exceptional',\n",
    "        'special': ['Infrared vision', 'Vomeronasal organ'],\n",
    "        'color_receptors': 2,\n",
    "        'desc': 'Pit organs detect infrared radiation (heat)! Can \"see\" warm-blooded '\n",
    "                'prey in darkness. Forked tongue collects chemical cues. Jacobson\\'s '\n",
    "                'organ analyzes scent particles.'\n",
    "    },\n",
    "    'Elephant': {\n",
    "        'vision_nm': [400, 700],\n",
    "        'hearing_hz': [1, 12000],  # Infrasound!\n",
    "        'olfactory': 'Exceptional',\n",
    "        'special': ['Infrasound', 'Seismic detection'],\n",
    "        'color_receptors': 2,\n",
    "        'desc': 'Detects infrasound below 20Hz! Can communicate over 10km. '\n",
    "                'Feet detect seismic vibrations. Exceptional olfaction with '\n",
    "                '~2,000 olfactory receptor genes (most of any animal).'\n",
    "    },\n",
    "    'Cat': {\n",
    "        'vision_nm': [450, 700],\n",
    "        'hearing_hz': [45, 64000],\n",
    "        'olfactory': 'Good',\n",
    "        'special': ['Night vision'],\n",
    "        'color_receptors': 2,\n",
    "        'desc': 'Excellent night vision (6\u00d7 human sensitivity). Tapetum lucidum '\n",
    "                'reflects light. Wide field of view (200\u00b0). Ultrasonic hearing '\n",
    "                'detects rodent vocalizations.'\n",
    "    }\n",
    "}\n\n",
    "print(\"SENSORY CAPABILITIES DATABASE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total species: {len(species_sensory)}\\n\")\n\n",
    "for name, data in species_sensory.items():\n",
    "    print(f\"{name}:\")\n",
    "    if data['vision_nm']:\n",
    "        print(f\"  Vision: {data['vision_nm'][0]}-{data['vision_nm'][1]} nm\")\n",
    "    if data['hearing_hz']:\n",
    "        print(f\"  Hearing: {data['hearing_hz'][0]}-{data['hearing_hz'][1]} Hz\")\n",
    "    print(f\"  Color receptors: {data['color_receptors']}\")\n",
    "    if data['special']:\n",
    "        print(f\"  Special: {', '.join(data['special'])}\")\n",
    "    print()\n\n",
    "print(\"\u2713 Database ready for exploration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Visual Spectrum Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_vision(species_name):\n",
    "    \"\"\"Analyze visual capabilities\"\"\"\n",
    "    \n",
    "    if species_name not in species_sensory:\n",
    "        print(f\"Species not found\")\n",
    "        return\n",
    "    \n",
    "    sp = species_sensory[species_name]\n",
    "    \n",
    "    if not sp['vision_nm']:\n",
    "        print(f\"{species_name} has limited/no vision data\")\n",
    "        return\n",
    "    \n",
    "    # Create spectrum visualization\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Visible Spectrum Range', 'Color Receptor Count',\n",
    "                       'Comparison to Human', 'Special Abilities'),\n",
    "        specs=[[{'type': 'bar'}, {'type': 'indicator'}],\n",
    "               [{'type': 'bar'}, {'type': 'bar'}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Spectrum range\n",
    "    ranges = {\n",
    "        'UV': [200, 380],\n",
    "        'Violet': [380, 450],\n",
    "        'Blue': [450, 495],\n",
    "        'Green': [495, 570],\n",
    "        'Yellow': [570, 590],\n",
    "        'Orange': [590, 620],\n",
    "        'Red': [620, 750],\n",
    "        'IR': [750, 1000]\n",
    "    }\n",
    "    \n",
    "    colors_map = {\n",
    "        'UV': '#8B00FF',\n",
    "        'Violet': '#9400D3',\n",
    "        'Blue': '#0000FF',\n",
    "        'Green': '#00FF00',\n",
    "        'Yellow': '#FFFF00',\n",
    "        'Orange': '#FF7F00',\n",
    "        'Red': '#FF0000',\n",
    "        'IR': '#8B0000'\n",
    "    }\n",
    "    \n",
    "    can_see = []\n",
    "    colors = []\n",
    "    for band, rng in ranges.items():\n",
    "        # Check if species can see this band\n",
    "        if sp['vision_nm'][0] <= rng[1] and sp['vision_nm'][1] >= rng[0]:\n",
    "            can_see.append(1)\n",
    "            colors.append(colors_map[band])\n",
    "        else:\n",
    "            can_see.append(0)\n",
    "            colors.append('#CCCCCC')\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(ranges.keys()),\n",
    "        y=can_see,\n",
    "        marker_color=colors,\n",
    "        showlegend=False\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # 2. Color receptor gauge\n",
    "    fig.add_trace(go.Indicator(\n",
    "        mode=\"number+gauge\",\n",
    "        value=sp['color_receptors'],\n",
    "        title={'text': \"Receptors\"},\n",
    "        gauge={\n",
    "            'axis': {'range': [0, 16]},\n",
    "            'bar': {'color': '#3498DB'},\n",
    "            'steps': [\n",
    "                {'range': [0, 2], 'color': '#ECF0F1'},\n",
    "                {'range': [2, 3], 'color': '#D5DBDB'},\n",
    "                {'range': [3, 5], 'color': '#AED6F1'},\n",
    "                {'range': [5, 16], 'color': '#85C1E9'}\n",
    "            ]\n",
    "        }\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # 3. Comparison to human\n",
    "    human = species_sensory['Human']\n",
    "    comparison = {\n",
    "        'Range (nm)': sp['vision_nm'][1] - sp['vision_nm'][0],\n",
    "        'Human range': human['vision_nm'][1] - human['vision_nm'][0]\n",
    "    }\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(comparison.keys()),\n",
    "        y=list(comparison.values()),\n",
    "        marker_color=['#E74C3C', '#95A5A6'],\n",
    "        text=[f\"{v}nm\" for v in comparison.values()],\n",
    "        textposition='auto',\n",
    "        showlegend=False\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # 4. Special abilities\n",
    "    if sp['special']:\n",
    "        abilities = sp['special'][:4]\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=abilities,\n",
    "            x=[100] * len(abilities),\n",
    "            orientation='h',\n",
    "            marker_color='#9B59B6',\n",
    "            text=abilities,\n",
    "            textposition='inside',\n",
    "            showlegend=False\n",
    "        ), row=2, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Can See\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Range (nm)\", row=2, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=700,\n",
    "        title_text=f\"<b>{species_name} Visual System</b>\"\n",
    "    )\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"VISUAL ANALYSIS: {species_name}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Spectrum range: {sp['vision_nm'][0]}-{sp['vision_nm'][1]} nm\")\n",
    "    print(f\"Bandwidth: {sp['vision_nm'][1] - sp['vision_nm'][0]} nm\")\n",
    "    print(f\"Color receptors: {sp['color_receptors']}\")\n",
    "    print(f\"  (Human has 3 for comparison)\")\n",
    "    \n",
    "    # What can they see that we can't?\n",
    "    if sp['vision_nm'][0] < human['vision_nm'][0]:\n",
    "        print(f\"\\n\u2713 Can see UV light (below {human['vision_nm'][0]}nm)!\")\n",
    "    if sp['vision_nm'][1] > human['vision_nm'][1]:\n",
    "        print(f\"\\n\u2713 Can see into infrared (above {human['vision_nm'][1]}nm)!\")\n",
    "    \n",
    "    if sp['special']:\n",
    "        print(f\"\\nSpecial abilities: {', '.join(sp['special'])}\")\n",
    "    \n",
    "    print(f\"\\n{sp['desc']}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    fig.show()\n\n",
    "# Interface\n",
    "vision_species = [n for n in species_sensory.keys() if species_sensory[n]['vision_nm']]\n",
    "\n",
    "vision_dropdown = Dropdown(\n",
    "    options=sorted(vision_species),\n",
    "    value='Mantis Shrimp',\n",
    "    description='Species:',\n",
    "    style={'description_width': '80px'}\n",
    ")\n\n",
    "display(HTML(\"<h3>\ud83d\udc41\ufe0f Visual Spectrum Explorer</h3>\"))\n",
    "interact(analyze_vision, species_name=vision_dropdown);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Auditory Range Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_hearing(species_name):\n",
    "    \"\"\"Analyze hearing capabilities\"\"\"\n",
    "    \n",
    "    sp = species_sensory[species_name]\n",
    "    \n",
    "    if not sp['hearing_hz']:\n",
    "        print(f\"{species_name} has limited hearing data\")\n",
    "        return\n",
    "    \n",
    "    # Create comparison\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Frequency Range Comparison', 'Special Capabilities')\n",
    "    )\n",
    "    \n",
    "    # Compare all species\n",
    "    species_list = []\n",
    "    low_freq = []\n",
    "    high_freq = []\n",
    "    colors_list = []\n",
    "    \n",
    "    for name, data in species_sensory.items():\n",
    "        if data['hearing_hz']:\n",
    "            species_list.append(name)\n",
    "            low_freq.append(data['hearing_hz'][0])\n",
    "            high_freq.append(data['hearing_hz'][1])\n",
    "            colors_list.append('#E74C3C' if name == species_name else '#95A5A6')\n",
    "    \n",
    "    # Create range bars\n",
    "    for i, name in enumerate(species_list):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[low_freq[i], high_freq[i]],\n",
    "            y=[name, name],\n",
    "            mode='lines+markers',\n",
    "            line=dict(width=8 if name == species_name else 4, color=colors_list[i]),\n",
    "            marker=dict(size=10),\n",
    "            showlegend=False,\n",
    "            hovertemplate=f\"{name}<br>Range: {low_freq[i]}-{high_freq[i]} Hz<extra></extra>\"\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    # Add reference lines\n",
    "    fig.add_vline(x=20, line_dash=\"dash\", line_color=\"orange\", \n",
    "                  annotation_text=\"Human low\", row=1, col=1)\n",
    "    fig.add_vline(x=20000, line_dash=\"dash\", line_color=\"orange\",\n",
    "                  annotation_text=\"Human high\", row=1, col=1)\n",
    "    \n",
    "    # Special abilities\n",
    "    if sp['special']:\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=sp['special'],\n",
    "            x=[1] * len(sp['special']),\n",
    "            orientation='h',\n",
    "            marker_color='#3498DB',\n",
    "            showlegend=False\n",
    "        ), row=1, col=2)\n",
    "    \n",
    "    fig.update_xaxes(type=\"log\", title_text=\"Frequency (Hz)\", row=1, col=1)\n",
    "    fig.update_layout(height=600, title_text=f\"<b>{species_name} Hearing Analysis</b>\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"HEARING ANALYSIS: {species_name}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Range: {sp['hearing_hz'][0]:,}-{sp['hearing_hz'][1]:,} Hz\")\n",
    "    print(f\"Bandwidth: {sp['hearing_hz'][1] - sp['hearing_hz'][0]:,} Hz\")\n",
    "    \n",
    "    human = species_sensory['Human']\n",
    "    if sp['hearing_hz'][0] < human['hearing_hz'][0]:\n",
    "        print(f\"\\n\u2713 Can hear INFRASOUND (below {human['hearing_hz'][0]} Hz)!\")\n",
    "    if sp['hearing_hz'][1] > human['hearing_hz'][1]:\n",
    "        print(f\"\u2713 Can hear ULTRASOUND (above {human['hearing_hz'][1]:,} Hz)!\")\n",
    "    \n",
    "    print(f\"\\n{sp['desc']}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    fig.show()\n\n",
    "hearing_species = [n for n in species_sensory if species_sensory[n]['hearing_hz']]\n",
    "\n",
    "hearing_dropdown = Dropdown(\n",
    "    options=sorted(hearing_species),\n",
    "    value='Dolphin',\n",
    "    description='Species:',\n",
    "    style={'description_width': '80px'}\n",
    ")\n\n",
    "display(HTML(\"<h3>\ud83d\udc42 Auditory Range Explorer</h3>\"))\n",
    "interact(analyze_hearing, species_name=hearing_dropdown);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Multi-Sensory Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_senses():\n",
    "    \"\"\"Compare sensory capabilities across all species\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Color Receptors', 'Visual Range (nm)',\n",
    "                       'Hearing Range (Hz)', 'Special Abilities Count'),\n",
    "        specs=[[{'type': 'bar'}, {'type': 'bar'}],\n",
    "               [{'type': 'bar'}, {'type': 'bar'}]]\n",
    "    )\n",
    "    \n",
    "    # Prepare data\n",
    "    species_names = list(species_sensory.keys())\n",
    "    receptors = [species_sensory[s]['color_receptors'] for s in species_names]\n",
    "    \n",
    "    # 1. Color receptors\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=species_names,\n",
    "        y=receptors,\n",
    "        marker_color='#9B59B6',\n",
    "        text=receptors,\n",
    "        textposition='outside',\n",
    "        showlegend=False\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # 2. Visual range\n",
    "    visual_ranges = []\n",
    "    for s in species_names:\n",
    "        if species_sensory[s]['vision_nm']:\n",
    "            vr = species_sensory[s]['vision_nm']\n",
    "            visual_ranges.append(vr[1] - vr[0])\n",
    "        else:\n",
    "            visual_ranges.append(0)\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=species_names,\n",
    "        y=visual_ranges,\n",
    "        marker_color='#3498DB',\n",
    "        showlegend=False\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # 3. Hearing range (log scale)\n",
    "    hearing_ranges = []\n",
    "    for s in species_names:\n",
    "        if species_sensory[s]['hearing_hz']:\n",
    "            hr = species_sensory[s]['hearing_hz']\n",
    "            hearing_ranges.append(hr[1] - hr[0])\n",
    "        else:\n",
    "            hearing_ranges.append(0)\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=species_names,\n",
    "        y=hearing_ranges,\n",
    "        marker_color='#E74C3C',\n",
    "        showlegend=False\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # 4. Special abilities count\n",
    "    special_counts = [len(species_sensory[s]['special']) for s in species_names]\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=species_names,\n",
    "        y=special_counts,\n",
    "        marker_color='#2ECC71',\n",
    "        text=special_counts,\n",
    "        textposition='outside',\n",
    "        showlegend=False\n",
    "    ), row=2, col=2)\n",
    "    \n",
    "    # Update layout\n",
    "    for i in range(1, 3):\n",
    "        for j in range(1, 3):\n",
    "            fig.update_xaxes(tickangle=45, row=i, col=j)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Range (nm)\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Range (Hz)\", type=\"log\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Count\", row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text='<b>Complete Sensory Comparison</b>'\n",
    "    )\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\nCOMPLETE SENSORY CAPABILITIES\")\n",
    "    print(\"=\"*90)\n",
    "    print(f\"{'Species':<18}{'Color':<8}{'Vision':<15}{'Hearing':<20}{'Special':<25}\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    for name in species_names:\n",
    "        sp = species_sensory[name]\n",
    "        vis = f\"{sp['vision_nm'][0]}-{sp['vision_nm'][1]}\" if sp['vision_nm'] else \"N/A\"\n",
    "        hear = f\"{sp['hearing_hz'][0]}-{sp['hearing_hz'][1]}\" if sp['hearing_hz'] else \"N/A\"\n",
    "        spec = ', '.join(sp['special'][:2]) if sp['special'] else \"None\"\n",
    "        print(f\"{name:<18}{sp['color_receptors']:<8}{vis:<15}{hear:<20}{spec:<25}\")\n",
    "    \n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    fig.show()\n\n",
    "compare_btn = Button(\n",
    "    description='\ud83d\udcca Compare All',\n",
    "    button_style='info',\n",
    "    layout={'width': '180px'}\n",
    ")\n",
    "\n",
    "output_compare = Output()\n",
    "\n",
    "def on_compare(b):\n",
    "    with output_compare:\n",
    "        clear_output(wait=True)\n",
    "        compare_all_senses()\n",
    "\n",
    "compare_btn.on_click(on_compare)\n",
    "\n",
    "display(HTML(\"<h3>\ud83d\udcca Multi-Sensory Comparison</h3>\"))\n",
    "display(compare_btn)\n",
    "display(output_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Challenge Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Design a Predator \ud83e\udd85\n\n",
    "**Scenario**: You're designing the ultimate predator for hunting small prey.\n\n",
    "**Requirements**:\n",
    "- Must hunt at night\n",
    "- Must detect prey from distance\n",
    "- Must locate prey in 3D space\n\n",
    "**Questions**:\n",
    "1. Which sensory system(s) would you prioritize?\n",
    "2. Compare owl vs bat vs snake - which is best?\n",
    "3. What trade-offs are involved?\n\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Best choices**:\n",
    "- **Owl**: Night vision + asymmetric ears = visual + auditory 3D location\n",
    "- **Bat**: Ultrasonic echolocation = precise distance + motion\n",
    "- **Snake**: Infrared vision = detects warm-blooded prey through barriers\n\n",
    "**Trade-offs**:\n",
    "- Vision: Silent but requires some light\n",
    "- Echolocation: Works in total darkness but reveals presence\n",
    "- Infrared: Detects heat but lower resolution\n\n",
    "**Optimal**: Owl-style combination (vision + hearing) for versatility!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1 workspace\n",
    "print(\"CHALLENGE 1: DESIGN A PREDATOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "predators = ['Owl', 'Bat', 'Snake (Pit Viper)']\n",
    "\n",
    "for pred in predators:\n",
    "    sp = species_sensory[pred]\n",
    "    print(f\"\\n{pred}:\")\n",
    "    print(f\"  Special: {', '.join(sp['special'])}\")\n",
    "    if sp['hearing_hz']:\n",
    "        print(f\"  Hearing: {sp['hearing_hz'][0]}-{sp['hearing_hz'][1]:,} Hz\")\n",
    "    print(f\"  Description: {sp['desc'][:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"YOUR DESIGN:\")\n",
    "print(\"-\"*70)\n",
    "print(\"Which sensory systems would you combine?\")\n",
    "print(\"What prey and environment would this work best for?\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Underwater Communication \ud83d\udc2c\n\n",
    "**Question**: Why do dolphins use echolocation instead of vision underwater?\n\n",
    "Compare:\n",
    "- Light penetration: ~200m in clear water\n",
    "- Sound propagation: Kilometers underwater\n",
    "- Dolphin hearing: Up to 150kHz\n\n",
    "**Analysis**:\n",
    "1. What are advantages of sound over light underwater?\n",
    "2. Why high frequency (ultrasound)?\n",
    "3. What can dolphins \"see\" that we can't?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**Sound advantages underwater**:\n",
    "1. Travels 4\u00d7 faster than in air\n",
    "2. Penetrates kilometers (vs 200m for light)\n",
    "3. Works in murky/dark water\n",
    "4. Can \"see\" inside objects (material discrimination!)\n",
    "\n",
    "**High frequency benefits**:\n",
    "- Better resolution (wavelength = 1cm at 150kHz)\n",
    "- Detect small fish and texture\n",
    "- Less interference from low-frequency ocean noise\n",
    "\n",
    "**Dolphins can detect**:\n",
    "- Internal structure of objects\n",
    "- Material composition\n",
    "- Hollow vs solid\n",
    "- Air-filled swim bladders in fish\n\n",
    "It's like having X-ray vision plus sonar!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: The Mantis Shrimp Mystery \ud83e\udd90\n\n",
    "**Paradox**: Mantis shrimp have 16 color receptors but WORSE color discrimination than humans (who have only 3)!\n\n",
    "**Question**: Why would evolution create 16 receptors if not for better color vision?\n\n",
    "**Hints**:\n",
    "- Humans: 3 receptors, brain compares signals = millions of colors\n",
    "- Mantis shrimp: 16 receptors, minimal processing = ~12 colors\n",
    "- Mantis shrimp need FAST responses (hunt with explosive strikes)\n\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "**The answer: SPEED vs PRECISION trade-off!**\n\n",
    "**Human system**:\n",
    "- 3 receptors \u2192 brain calculates differences \u2192 slow but precise\n",
    "- Process: ~50ms to perceive color\n",
    "- Result: Millions of distinguishable colors\n\n",
    "**Mantis shrimp system**:\n",
    "- 16 receptors \u2192 direct recognition (no calculation!) \u2192 ultra-fast\n",
    "- Process: ~5ms to perceive color\n",
    "- Result: Only ~12 color categories but 10\u00d7 faster!\n\n",
    "**Why it matters**:\n",
    "- Mantis shrimp strike at 50mph\n",
    "- Need instant target recognition\n",
    "- Don't need subtle color distinctions\n",
    "- Need fast \"friend vs foe vs food\" decisions\n\n",
    "**Lesson**: More receptors \u2260 better vision. Evolution optimizes for WHAT MATTERS!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Export Your Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results():\n",
    "    \"\"\"Export sensory analysis results\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = \"/content\"\n",
    "    \n",
    "    # Create summary data\n",
    "    data = []\n",
    "    for name, sp in species_sensory.items():\n",
    "        data.append({\n",
    "            'Species': name,\n",
    "            'Color_Receptors': sp['color_receptors'],\n",
    "            'Vision_Min_nm': sp['vision_nm'][0] if sp['vision_nm'] else None,\n",
    "            'Vision_Max_nm': sp['vision_nm'][1] if sp['vision_nm'] else None,\n",
    "            'Hearing_Min_Hz': sp['hearing_hz'][0] if sp['hearing_hz'] else None,\n",
    "            'Hearing_Max_Hz': sp['hearing_hz'][1] if sp['hearing_hz'] else None,\n",
    "            'Olfaction': sp['olfactory'],\n",
    "            'Special_Abilities': ', '.join(sp['special']) if sp['special'] else 'None'\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save CSV\n",
    "    csv_file = f\"{output_dir}/lab_9_2_sensory_data_{timestamp}.csv\"\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"\u2713 Data saved: {csv_file}\")\n",
    "    \n",
    "    # Create summary visualization\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Color Receptors', 'Special Abilities')\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df['Species'],\n",
    "        y=df['Color_Receptors'],\n",
    "        marker_color='#9B59B6',\n",
    "        text=df['Color_Receptors'],\n",
    "        textposition='outside'\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    special_counts = [len(sp['special']) for sp in species_sensory.values()]\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(species_sensory.keys()),\n",
    "        y=special_counts,\n",
    "        marker_color='#2ECC71',\n",
    "        text=special_counts,\n",
    "        textposition='outside'\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    fig.update_xaxes(tickangle=45, row=1, col=1)\n",
    "    fig.update_xaxes(tickangle=45, row=1, col=2)\n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        title_text='<b>Lab 9.2 Summary: Sensory System Analysis</b>',\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    html_file = f\"{output_dir}/lab_9_2_summary_{timestamp}.html\"\n",
    "    fig.write_html(html_file)\n",
    "    print(f\"\u2713 Visualization saved: {html_file}\")\n",
    "    \n",
    "    try:\n",
    "        png_file = f\"{output_dir}/lab_9_2_summary_{timestamp}.png\"\n",
    "        fig.write_image(png_file, width=1200, height=600)\n",
    "        print(f\"\u2713 PNG saved: {png_file}\")\n",
    "    except:\n",
    "        print(\"\u2139 PNG export requires kaleido (optional)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXPORT COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Files saved to: {output_dir}\")\n",
    "    print(\"\\nTo download:\")\n",
    "    print(\"1. Click folder icon \ud83d\udcc1 on left\")\n",
    "    print(\"2. Files in main /content folder\")\n",
    "    print(\"3. Right-click \u2192 Download\")\n",
    "    print(\"\\n\u2713 Results ready!\")\n\n",
    "export_btn = Button(\n",
    "    description='\ud83d\udce5 Export Results',\n",
    "    button_style='success',\n",
    "    icon='download',\n",
    "    layout={'width': '200px'}\n",
    ")\n",
    "\n",
    "export_btn.on_click(lambda b: export_results())\n",
    "\n",
    "display(HTML(\"<h3>\ud83d\udce4 Export Your Work</h3>\"))\n",
    "display(export_btn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Reflection\n\n",
    "### What You've Learned\n\n",
    "\u2705 **Sensory diversity** - Vertebrates detect vastly different ranges  \n",
    "\u2705 **Vision systems** - From 1 to 16 color receptors  \n",
    "\u2705 **Hearing ranges** - Infrasound to ultrasound  \n",
    "\u2705 **Special senses** - Echolocation, electroreception, infrared  \n",
    "\u2705 **Trade-offs** - Speed vs precision, range vs resolution  \n\n",
    "### Key Insights\n\n",
    "**Surprising findings**:\n",
    "- Mantis shrimp: 16 receptors but worse color vision than humans!\n",
    "- Dolphins: \"See\" inside objects with echolocation\n",
    "- Elephants: Communicate over 10km with infrasound\n",
    "- Salmon: Navigate by scent to exact birthplace after years\n\n",
    "**Patterns**:\n",
    "1. Sensory systems match ecological needs\n",
    "2. Trade-offs between different capabilities\n",
    "3. Multiple solutions to same problem (night hunting)\n",
    "4. More receptors \u2260 better (mantis shrimp paradox)\n\n",
    "### Connection to Chapter 9\n\n",
    "This lab illustrated **Section 9.4** concepts:\n",
    "- Universal sensory principles (transduction, processing)\n",
    "- Sensory specializations across species\n",
    "- Pattern recognition in sensory systems\n",
    "- Ecological adaptations\n\n",
    "### Real-World Applications\n\n",
    "- **Robotics**: Biomimetic sensors (bat-inspired sonar)\n",
    "- **Medicine**: Cochlear implants from hearing research\n",
    "- **Technology**: Camera sensors from animal vision\n",
    "- **Conservation**: Understanding species' perceptual worlds\n",
    "- **AI**: Computer vision from biological principles\n\n",
    "### The Big Picture\n\n",
    "Animals don't experience one \"real\" world - they each perceive different realities:\n",
    "- Mantis shrimp see polarized UV light\n",
    "- Dolphins \"see\" with sound\n",
    "- Sharks sense electric fields\n",
    "- Dogs smell in technicolor\n\n",
    "Evolution optimizes senses for what matters to survival, not for \"perfection\"!\n\n",
    "**Congratulations on completing Lab 9.2!** \ud83c\udf89\n\n",
    "You now understand why the world looks, sounds, and smells so different across species!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}